{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x7f521ce88dd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "\n",
    "from distkeras.trainers import *\n",
    "from distkeras.predictors import *\n",
    "from distkeras.transformers import *\n",
    "from distkeras.evaluators import *\n",
    "from distkeras.utils import *\n",
    "import distkeras.utils\n",
    "from distkeras.job_deployment import Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 500)               8000      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 14)                7014      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 14)                0         \n",
      "=================================================================\n",
      "Total params: 265,514\n",
      "Trainable params: 265,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_executors = 2\n",
    "num_cores = 3\n",
    "num_workers = num_executors * num_cores\n",
    "optimizer = 'adagrad'\n",
    "loss = 'categorical_crossentropy'\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_shape=(15,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(14))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "from distkeras.job_deployment import graph\n",
    "graph.append(tf.get_default_graph())\n",
    "\n",
    "trainer = AEASGD(keras_model=model, worker_optimizer=optimizer, loss=loss, num_workers=num_workers, \n",
    "                 batch_size=32, features_col=\"features_normalized\", label_col=\"newlabel\", num_epoch=1,\n",
    "                 communication_window=32, rho=5.0, learning_rate=0.1, master_port=5004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job = Job(\"3Q20LA3MXU3N8Y9NVJ7A1T5WNHL2IWQSNNJ5V9I5P7MRJ8LSC33EN2DT3EWYLCJA\",\n",
    "          \"user1\",\n",
    "          \"data_path/training_set.parquet\",\n",
    "          1,\n",
    "          1,\n",
    "          trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda2/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda2/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/distkeras/job_deployment.py\", line 518, in run\n",
      "    while not self.is_finished():\n",
      "  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/distkeras/job_deployment.py\", line 443, in is_finished\n",
      "    response = urllib2.urlopen(request)\n",
      "  File \"/home/ubuntu/anaconda2/lib/python2.7/urllib2.py\", line 154, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "  File \"/home/ubuntu/anaconda2/lib/python2.7/urllib2.py\", line 429, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/home/ubuntu/anaconda2/lib/python2.7/urllib2.py\", line 447, in _open\n",
      "    '_open', req)\n",
      "  File \"/home/ubuntu/anaconda2/lib/python2.7/urllib2.py\", line 407, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/home/ubuntu/anaconda2/lib/python2.7/urllib2.py\", line 1228, in http_open\n",
      "    return self.do_open(httplib.HTTPConnection, req)\n",
      "  File \"/home/ubuntu/anaconda2/lib/python2.7/urllib2.py\", line 1198, in do_open\n",
      "    raise URLError(err)\n",
      "URLError: <urlopen error [Errno 111] Connection refused>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "job.send_with_files('http://172.31.31.105:8004', ['generator_images.py', 'insertData.py'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_info = [(1024, 30, 32, 32, 14)]\n",
    "names = ['steps_per_epoch', 'num_epoch', 'batch_size', 'communication_window', 'num_workers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = sqlContext.createDataFrame(train_info*14, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+----------+--------------------+-----------+\n",
      "|steps_per_epoch|num_epoch|batch_size|communication_window|num_workers|\n",
      "+---------------+---------+----------+--------------------+-----------+\n",
      "|           1024|       30|        32|                  32|         14|\n",
      "|           1024|       30|        32|                  32|         14|\n",
      "|           1024|       30|        32|                  32|         14|\n",
      "|           1024|       30|        32|                  32|         14|\n",
      "|           1024|       30|        32|                  32|         14|\n",
      "|           1024|       30|        32|                  32|         14|\n",
      "|           1024|       30|        32|                  32|         14|\n",
      "|           1024|       30|        32|                  32|         14|\n",
      "|           1024|       30|        32|                  32|         14|\n",
      "|           1024|       30|        32|                  32|         14|\n",
      "|           1024|       30|        32|                  32|         14|\n",
      "|           1024|       30|        32|                  32|         14|\n",
      "|           1024|       30|        32|                  32|         14|\n",
      "|           1024|       30|        32|                  32|         14|\n",
      "+---------------+---------+----------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
